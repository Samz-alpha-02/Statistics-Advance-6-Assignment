{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b17aa7-a088-40cd-b911-76cbc1f57e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1\n",
    "Analysis of Variance (ANOVA) is a statistical technique used to compare means across multiple groups\n",
    "or treatments. To use ANOVA effectively, certain assumptions must be met. Violations of these assumptions\n",
    "can impact the validity of the results. The key assumptions for ANOVA are:\n",
    "\n",
    "1.Independence: Observations within and between groups should be independent of each other. In experimental\n",
    "designs, this means that the treatment or condition assigned to one subject should not affect another\n",
    "subject's response. Violation: If observations are not independent (e.g., repeated measures on the same \n",
    "subject without proper modeling), it can lead to inflated Type I error rates.\n",
    "\n",
    "2.Normality: The residuals (differences between observed values and group means) should follow a normal \n",
    "distribution. This assumption primarily applies to the residuals, not necessarily the original data. \n",
    "Violation: Departures from normality can result in misleading p-values and confidence intervals. If \n",
    "data are strongly non-normal, it may be necessary to transform the data or consider non-parametric tests.\n",
    "\n",
    "3.Homogeneity of Variance (Homoscedasticity): The variance of residuals should be roughly equal across \n",
    "groups. Violation: Heteroscedasticity (unequal variances) can lead to unreliable ANOVA results. If \n",
    "variances are significantly different, consider using robust ANOVA methods or transformations.\n",
    "\n",
    "Examples of violations and their impact:\n",
    "\n",
    "1.Non-normality: If the residuals are not normally distributed, it can lead to incorrect p-values and \n",
    "confidence intervals. For example, if you have count data with many zeros, you might encounter non-normality,\n",
    "and using ANOVA without appropriate transformations could lead to errors.\n",
    "\n",
    "2.Heteroscedasticity: If the assumption of equal variances is violated, ANOVA may produce incorrect results.\n",
    "For instance, in a study comparing the impact of two teaching methods on student scores, if one method \n",
    "consistently shows more variation in scores, it can lead to a biased conclusion.\n",
    "\n",
    "3.Lack of Independence: In longitudinal studies or clustered data, failing to account for dependencies\n",
    "among observations can result in incorrect p-values. For example, in a study measuring blood pressure \n",
    "across time points within the same individuals, ignoring this dependency can lead to underestimated \n",
    "standard errors.\n",
    "\n",
    "Addressing Assumption Violations:\n",
    "\n",
    "1.Transformations: If data violate normality or homoscedasticity, transforming the data \n",
    "(e.g., using logarithms) may help meet these assumptions.\n",
    "\n",
    "2.Non-parametric Tests: If normality and equal variance assumptions cannot be met, consider non-parametric\n",
    "tests like the Kruskal-Wallis test, which do not rely on these assumptions.\n",
    "\n",
    "3.Robust Methods: Robust ANOVA methods can be used when there are concerns about non-normality and \n",
    "heteroscedasticity.\n",
    "\n",
    "4.Mixed-Design ANOVA: For repeated measures or clustered data, using mixed-design ANOVA models that account\n",
    "for dependencies is appropriate.\n",
    "\n",
    "It's important to assess these assumptions before interpreting ANOVA results to ensure the validity and \n",
    "reliability of your conclusions. Violations should be addressed or alternative methods considered when \n",
    "assumptions are not met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaffb6e-9f46-4939-a5b9-15765e7f30e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c4b6da-f15e-49f7-bfc5-05e52d90d6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2\n",
    "Analysis of Variance (ANOVA) is a statistical technique used to analyze the differences among group\n",
    "means in a dataset. There are three main types of ANOVA, each suited for different situations:\n",
    "\n",
    "One-Way ANOVA:\n",
    "\n",
    "Situation: One-Way ANOVA is used when you want to compare the means of three or more independent \n",
    "(unrelated) groups or treatments. It answers the question of whether there are statistically \n",
    "significant differences among these groups.\n",
    "Example: You have four different types of fertilizers, and you want to test if they result in \n",
    "significantly different crop yields.\n",
    "\n",
    "Two-Way ANOVA:\n",
    "\n",
    "Situation: Two-Way ANOVA is used when you want to simultaneously analyze the effects of two independent\n",
    "categorical variables (factors) on a dependent variable. It helps determine if there are main effects of\n",
    "each factor and whether there is an interaction effect between them.\n",
    "Example: You want to study the effects of both diet type (Factor A: low-fat, high-fat) and exercise \n",
    "frequency (Factor B: sedentary, moderate, intense) on weight loss.\n",
    "\n",
    "Repeated Measures ANOVA:\n",
    "\n",
    "Situation: Repeated Measures ANOVA is used when you have a within-subjects design, meaning you collect\n",
    "multiple measurements from the same subjects under different conditions or time points. It helps determine \n",
    "if there are significant differences across these conditions or time points.\n",
    "Example: You measure the blood pressure of the same individuals before and after they undergo three \n",
    "different stress tests.\n",
    "\n",
    "Additional Notes:\n",
    "\n",
    "Factor: In ANOVA, a factor is a categorical independent variable that defines the groups or conditions\n",
    "you are comparing.\n",
    "Level: Each category within a factor is called a level. For example, if you have a factor \"Treatment\" \n",
    "with levels \"A,\" \"B,\" and \"C,\" you have three levels.\n",
    "Interaction Effect: Two-Way ANOVA assesses whether the interaction between two factors (e.g., Diet and Exercise) \n",
    "significantly affects the dependent variable. It tells you if the combination of factors has a different\n",
    "impact than you would expect based on their individual effects.\n",
    "\n",
    "In summary, One-Way ANOVA is used for comparing means across multiple independent groups, Two-Way ANOVA\n",
    "assesses the effects of two independent factors, and Repeated Measures ANOVA analyzes differences across\n",
    "repeated measurements within the same subjects. The choice of ANOVA type depends on the research design \n",
    "and the specific hypotheses you want to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94aaa65a-f9b7-46d9-b822-fddf24ef0305",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e30ff9-dca0-434b-b683-ee00309061a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3\n",
    "The partitioning of variance in Analysis of Variance (ANOVA) is a fundamental concept in statistics\n",
    "that helps researchers understand how the total variability in a dataset can be attributed to different\n",
    "sources or factors. ANOVA is a statistical technique used to analyze and compare means among two or more\n",
    "groups or treatments to determine if there are significant differences between them. Understanding the \n",
    "partitioning of variance is essential in ANOVA because it provides insights into the sources of variability\n",
    "and allows researchers to draw conclusions about the significance of the factors being studied.\n",
    "\n",
    "In ANOVA, the total variability in the data is decomposed or partitioned into different components:\n",
    "\n",
    "Total Variance (Total Sum of Squares, SST): This represents the overall variability in the data, which is\n",
    "calculated as the sum of the squared differences between each data point and the overall mean of all the data \n",
    "points.\n",
    "\n",
    "Between-Group Variance (Between-Group Sum of Squares, SSB): This represents the variability that can be \n",
    "attributed to differences between the group means. It is calculated as the sum of the squared differences\n",
    "between each group mean and the overall mean.\n",
    "\n",
    "Within-Group Variance (Within-Group Sum of Squares, SSW): This represents the variability within each group \n",
    "or treatment. It is calculated as the sum of the squared differences between each individual data point and \n",
    "its group mean.\n",
    "\n",
    "The partitioning of variance helps researchers answer questions such as:\n",
    "\n",
    "Are the group means significantly different from each other? (This is determined by comparing the \n",
    "Between-Group Variance to the Within-Group Variance.)\n",
    "\n",
    "What proportion of the total variability can be explained by the group differences? (This is often \n",
    "expressed as the \"explained variance\" or the \"effect size.\")\n",
    "\n",
    "How much of the total variability is due to random or unexplained factors? (This is often referred to \n",
    "as \"unexplained variance\" or \"error variance.\")\n",
    "\n",
    "Is the observed difference between group means statistically significant? (This is determined by comparing \n",
    "the Between-Group Variance to the Within-Group Variance and considering the degrees of freedom.)\n",
    "\n",
    "Understanding the partitioning of variance allows researchers to assess the significance of the factors \n",
    "they are studying and determine if there is evidence to support their hypotheses. It is a powerful tool \n",
    "for comparing multiple groups and making informed decisions about whether the differences observed are \n",
    "likely to be due to real effects or simply random variation. In essence, ANOVA helps researchers quantify\n",
    "and attribute sources of variation, which is critical in fields such as experimental research, social sciences,\n",
    "and many other areas of scientific inquiry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec30f0cc-53ad-48fe-9958-557d0e165c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7923825-e93c-4928-9c23-07cbd13b2ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 450.93333333333334\n",
      "Explained Sum of Squares (SSE): 373.7333333333335\n",
      "Residual Sum of Squares (SSR): 77.19999999999999\n"
     ]
    }
   ],
   "source": [
    "#Q4\n",
    "import numpy as np\n",
    "\n",
    "group1 = np.array([22, 24, 28, 20, 25])\n",
    "group2 = np.array([30, 32, 28, 34, 29])\n",
    "group3 = np.array([18, 16, 20, 21, 17])\n",
    "\n",
    "data = [group1, group2, group3]\n",
    "\n",
    "grand_mean = np.mean(np.concatenate(data))\n",
    "\n",
    "sst = np.sum([(x - grand_mean)**2 for group_data in data for x in group_data])\n",
    "\n",
    "sse = np.sum([len(group_data) * (np.mean(group_data) - grand_mean)**2 for group_data in data])\n",
    "\n",
    "ssr = np.sum([(x - np.mean(group_data))**2 for group_data in data for x in group_data])\n",
    "\n",
    "print(\"Total Sum of Squares (SST):\", sst)\n",
    "print(\"Explained Sum of Squares (SSE):\", sse)\n",
    "print(\"Residual Sum of Squares (SSR):\", ssr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58523ee-df72-4fe6-a154-697937004e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65807fbd-feb2-45cf-ad68-553f6839bb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Effect of Fertilizer: 0.033333333333333735\n",
      "Main Effect of Watering: 0.000368594289958913\n",
      "Interaction Effect: 0.040865910536107684\n"
     ]
    }
   ],
   "source": [
    "#Q5\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a dataframe\n",
    "dataframe = pd.DataFrame({'Fertilizer': np.repeat(['daily', 'weekly'], 15),\n",
    "                          'Watering': np.repeat(['daily', 'weekly'], 15),\n",
    "                          'height': [14, 16, 15, 15, 16, 13, 12, 11,\n",
    "                                     14, 15, 16, 16, 17, 18, 14, 13,\n",
    "                                     14, 14, 14, 15, 16, 16, 17, 18,\n",
    "                                     14, 13, 14, 14, 14, 15]})\n",
    "\n",
    "# Performing two-way ANOVA\n",
    "model = ols('height ~ C(Fertilizer) + C(Watering) + C(Fertilizer):C(Watering)',\n",
    "            data=dataframe).fit()\n",
    "result = sm.stats.anova_lm(model, type=2)\n",
    "\n",
    "# Calculate the main effects and interaction effect\n",
    "main_effect_Fertilizer = result.loc['C(Fertilizer)', 'sum_sq'] / result.loc['C(Fertilizer)', 'df']\n",
    "main_effect_Watering = result.loc['C(Watering)', 'sum_sq'] / result.loc['C(Watering)', 'df']\n",
    "interaction_effect = result.loc['C(Fertilizer):C(Watering)', 'sum_sq'] / result.loc['C(Fertilizer):C(Watering)', 'df']\n",
    "\n",
    "# Print the results\n",
    "print(\"Main Effect of Fertilizer:\", main_effect_Fertilizer)\n",
    "print(\"Main Effect of Watering:\", main_effect_Watering)\n",
    "print(\"Interaction Effect:\", interaction_effect)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c69861-f942-423c-b3f5-b7eb8a28de4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95181f9-b94f-4e2d-9cc5-db73ee1beab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6\n",
    "In a one-way ANOVA, the F-statistic is used to assess whether there are significant differences\n",
    "among the means of three or more groups. The p-value associated with the F-statistic helps determine\n",
    "the statistical significance of these differences.\n",
    "\n",
    "In your scenario, you obtained an F-statistic of 5.23 and a p-value of 0.02. To interpret these results:\n",
    "\n",
    "Null Hypothesis (H0): The null hypothesis in a one-way ANOVA is that there are no significant \n",
    "differences among the group means. In other words, all the group means are equal.\n",
    "\n",
    "Alternative Hypothesis (Ha): The alternative hypothesis is that at least one group mean is \n",
    "significantly different from the others.\n",
    "\n",
    "Based on the given F-statistic and p-value:\n",
    "\n",
    "The F-statistic (5.23) indicates the ratio of the variance between groups to the variance within groups.\n",
    "A larger F-statistic suggests greater variability between groups relative to within groups.\n",
    "\n",
    "The p-value (0.02) is the probability of observing such a result (or more extreme) if the null hypothesis\n",
    "were true. In other words, it indicates the strength of evidence against the null hypothesis.\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "Since the p-value (0.02) is less than the typical significance level (e.g., 0.05), we reject the null \n",
    "hypothesis (H0) at the 0.05 significance level.\n",
    "\n",
    "This suggests that there is strong evidence to conclude that at least one group mean is significantly\n",
    "different from the others.\n",
    "\n",
    "However, the ANOVA itself doesn't tell you which specific groups are different; it only tells you that \n",
    "there are differences somewhere among the groups. You would need to follow up with post hoc tests \n",
    "(e.g., Tukey's HSD, Bonferroni, etc.) to determine which specific group(s) differ from each other.\n",
    "\n",
    "In summary, based on the results of the one-way ANOVA, you can conclude that there are significant\n",
    "differences among the groups. Further analysis is needed to identify which groups are different from \n",
    "each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01db77eb-3e9e-4a7b-b7bd-8e84cecf48e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a610bded-43aa-4959-be2d-d17c8b8ba66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7\n",
    "Handling missing data in a repeated measures ANOVA is crucial to ensure the validity and reliability \n",
    "of your analysis. Repeated measures ANOVA involves measuring the same subjects or entities multiple times,\n",
    "and missing data can occur for various reasons, such as dropout, non-response, or technical errors. Here \n",
    "are some common methods for handling missing data in repeated measures ANOVA and their potential consequences:\n",
    "\n",
    "1.Complete Case Analysis (Listwise Deletion):\n",
    "\n",
    "In this approach, any subject with missing data on any time point is excluded from the analysis.\n",
    "Pros:\n",
    "Simple and straightforward.\n",
    "Preserves the sample size for those with complete data.\n",
    "Cons:\n",
    "Reduces sample size, potentially leading to a loss of statistical power.\n",
    "May introduce bias if the missing data are not missing completely at random (MCAR).\n",
    "\n",
    "2.Mean Imputation:\n",
    "\n",
    "Replace missing values with the mean of observed values for that variable.\n",
    "Pros:\n",
    "Preserves sample size.\n",
    "Easy to implement.\n",
    "Cons:\n",
    "Underestimates the variability in the data, potentially leading to overly optimistic p-values.\n",
    "Can introduce bias if data are not MCAR.\n",
    "Does not account for within-subject correlation over time.\n",
    "\n",
    "3.Linear Interpolation or Last Observation Carried Forward (LOCF):\n",
    "\n",
    "Linear interpolation fills missing values with estimates based on neighboring time points, or LOCF \n",
    "carries the last observed value forward.\n",
    "Pros:\n",
    "Preserves sample size.\n",
    "May provide more accurate estimates if data are missing due to linear trends.\n",
    "Cons:\n",
    "Assumes a linear trend between observed points, which may not be valid.\n",
    "LOCF can overestimate the effect of treatment.\n",
    "\n",
    "4.Multiple Imputation:\n",
    "\n",
    "Generates multiple complete datasets with imputed values and combines results.\n",
    "Pros:\n",
    "Preserves sample size.\n",
    "Accounts for uncertainty in imputation.\n",
    "Applicable for missing data that are not MCAR.\n",
    "Cons:\n",
    "More complex and computationally intensive.\n",
    "Requires specifying a model for imputation, which can be challenging.\n",
    "\n",
    "5.Mixed-Effects Models (Longitudinal Analysis):\n",
    "\n",
    "Uses all available data, including subjects with missing data at some time points.\n",
    "Pros:\n",
    "Accounts for within-subject correlation.\n",
    "Can handle data that are missing at random or missing not at random.\n",
    "Cons:\n",
    "Requires specialized software and statistical expertise.\n",
    "Results can be sensitive to the model assumptions.\n",
    "\n",
    "The choice of method for handling missing data should depend on the nature of the data and the reasons \n",
    "for missingness. It's essential to carefully consider the potential consequences of each method, \n",
    "including its impact on statistical power, bias, and the validity of conclusions drawn from the analysis.\n",
    "In practice, sensitivity analyses and exploring different methods can help assess the robustness of \n",
    "results to missing data handling techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da071705-4943-4a9d-bd8b-c838f3c0462d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b3d28e-10f0-4fcb-98b8-5f34531d9b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8\n",
    "Post-hoc tests are used after conducting an Analysis of Variance (ANOVA) to make pairwise comparisons \n",
    "between groups when the ANOVA reveals a significant difference among the group means. These tests help \n",
    "identify which specific group(s) differ from each other. Common post-hoc tests include:\n",
    "\n",
    "1.Tukey's Honestly Significant Difference (HSD):\n",
    "\n",
    "When to use: Tukey's HSD is a widely used post-hoc test and is appropriate when you have conducted a \n",
    "one-way ANOVA. It controls the familywise error rate and is suitable for comparing all possible pairs \n",
    "of groups.\n",
    "Example: In a study comparing the mean scores of three different teaching methods (A, B, and C) on \n",
    "student performance, a one-way ANOVA reveals a significant difference. Tukey's HSD can be used to \n",
    "determine which teaching methods differ significantly from each other.\n",
    "\n",
    "2.Bonferroni Correction:\n",
    "\n",
    "When to use: The Bonferroni correction is a conservative approach used when you have conducted multiple \n",
    "pairwise comparisons after an ANOVA (or any other test). It controls the overall Type I error rate by\n",
    "dividing the desired significance level (e.g., 0.05) by the number of comparisons.\n",
    "Example: Suppose you conducted 10 pairwise comparisons after a one-way ANOVA. To maintain an overall alpha\n",
    "level of 0.05, you can use a significance level of 0.05/10 = 0.005 for each individual comparison.\n",
    "\n",
    "3.Sidak Correction:\n",
    "\n",
    "When to use: Similar to the Bonferroni correction, the Sidak correction controls the overall Type I \n",
    "error rate but tends to be less conservative when conducting multiple comparisons.\n",
    "Example: If you have multiple comparisons to make after an ANOVA and want to control the familywise \n",
    "error rate, you can use the Sidak correction with a specified alpha level.\n",
    "\n",
    "4.Duncan's Multiple Range Test (MRT):\n",
    "\n",
    "When to use: Duncan's MRT is used when you have conducted a one-way ANOVA, and it provides more power \n",
    "than Tukey's HSD when group sizes are unequal. However, it does not control the familywise error rate.\n",
    "Example: In a study comparing the yields of different crop varieties, a one-way ANOVA indicates significant\n",
    "differences. Duncan's MRT can be used to group varieties with similar yields.\n",
    "\n",
    "5.Games-Howell Test:\n",
    "\n",
    "When to use: The Games-Howell test is suitable when group variances are unequal, and you have conducted a \n",
    "one-way ANOVA. It does not assume equal variances across groups, unlike Tukey's HSD.\n",
    "Example: In a study comparing the exam scores of students from different schools, a one-way ANOVA shows \n",
    "significant differences. The Games-Howell test can be applied when group variances are not equal.\n",
    "\n",
    "6.Holm-Bonferroni Method:\n",
    "\n",
    "When to use: The Holm-Bonferroni method is another correction method that controls the familywise error \n",
    "rate and can be applied to any situation with multiple comparisons.\n",
    "Example: After conducting multiple pairwise comparisons in various situations (e.g., clinical trials, \n",
    "market research), you can use the Holm-Bonferroni method to adjust significance levels while controlling \n",
    "the overall Type I error rate.\n",
    "\n",
    "When to use a specific post-hoc test depends on the characteristics of your data, the design of your study,\n",
    "and your desired level of control over Type I errors. The choice of a post-hoc test should align with the \n",
    "research question and the assumptions underlying the statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bc906b-78ff-433a-8448-33120dd741f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d45bcca5-5567-48b2-8876-339d78bc20de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 68.92282352941194\n",
      "p-value: 5.436714823633692e-14\n"
     ]
    }
   ],
   "source": [
    "#Q9\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Sample data for the three diets\n",
    "diet_A = [2.5, 3.2, 2.8, 3.5, 2.9, 3.7, 2.6, 3.0, 3.1, 2.8,\n",
    "          3.3, 3.4, 3.1, 2.7, 3.0]\n",
    "diet_B = [2.1, 2.4, 2.2, 2.5, 2.0, 2.6, 2.3, 2.7, 2.8, 2.2,\n",
    "          2.4, 2.5, 2.3, 2.6, 2.1]\n",
    "diet_C = [1.8, 1.9, 2.0, 1.7, 1.9, 1.8, 2.1, 2.0, 2.2, 1.6,\n",
    "          1.9, 1.8, 2.0, 2.1, 2.2]\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Print the results\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4e4664-d6ec-460d-ab7c-950c07d3550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Now, let's interpret the results:\n",
    "\n",
    "F-statistic: The F-statistic quantifies the ratio of the variability between the group means to \n",
    "the variability within the groups. A larger F-statistic suggests a greater likelihood of \n",
    "significant differences among the groups.\n",
    "\n",
    "p-value: The p-value associated with the F-statistic indicates the probability of obtaining the \n",
    "observed results if there were no true differences among the group means. A small p-value (typically \n",
    "less than 0.05) suggests that there are significant differences among the groups.\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "In your analysis, if the p-value is less than your chosen significance level (e.g., 0.05), you can \n",
    "reject the null hypothesis. This would suggest that there are significant differences in weight loss\n",
    "among the three diets (A, B, and C).\n",
    "\n",
    "Conversely, if the p-value is greater than your chosen significance level, you would fail to reject \n",
    "the null hypothesis, indicating that there is insufficient evidence to conclude that the mean weight \n",
    "loss differs significantly among the three diets.\n",
    "\n",
    "In summary, run the code and check the p-value to determine whether there are significant differences\n",
    "in weight loss among the three diets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c558a467-99f1-49ad-9cea-dc2ee9e9b024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1865c9c5-54e2-47e0-815d-62b354f07ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 sum_sq    df         F    PR(>F)\n",
      "C(Software)                   96.200000   2.0  0.208900  0.811897\n",
      "C(Experience)                 28.900000   1.0  0.125514  0.724018\n",
      "C(Software):C(Experience)    262.466667   2.0  0.569950  0.567725\n",
      "Residual                   19341.333333  84.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "#Q10\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data\n",
    "data = pd.DataFrame({\n",
    "    'Software': np.repeat(['A', 'B', 'C'], 30),\n",
    "    'Experience': np.tile(['Novice', 'Experienced'], 45),\n",
    "    'Time': np.random.randint(10, 60, 90)  # Random time data (replace with your data)\n",
    "})\n",
    "\n",
    "# Perform two-way ANOVA\n",
    "formula = 'Time ~ C(Software) + C(Experience) + C(Software):C(Experience)'\n",
    "model = ols(formula, data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Print the results\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208f7489-05ea-497d-b056-71fb5ba3899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Now, let's interpret the results from the ANOVA table:\n",
    "\n",
    "**Main Effect of Software (C(Software)):\n",
    "\n",
    "The F-statistic and p-value associated with C(Software) test whether there is a significant difference \n",
    "in task completion times among the different software programs (A, B, and C).\n",
    "A significant p-value indicates that there is a main effect of software, suggesting that at least one\n",
    "software program has a different average task completion time.\n",
    "\n",
    "**Main Effect of Experience (C(Experience)):\n",
    "\n",
    "The F-statistic and p-value associated with C(Experience) test whether there is a significant difference \n",
    "in task completion times between novice and experienced employees.\n",
    "A significant p-value suggests that there is a main effect of employee experience level, indicating that \n",
    "novice and experienced employees, on average, have different task completion times.\n",
    "\n",
    "**Interaction Effect (C(Software):C(Experience)):\n",
    "\n",
    "The F-statistic and p-value associated with C(Software):C(Experience) test whether there is an interaction \n",
    "effect between software programs and employee experience levels.\n",
    "A significant p-value for the interaction effect indicates that the effect of software on task completion \n",
    "times differs depending on the employee's experience level.\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "If the p-values associated with any of the main effects (C(Software) or C(Experience)) are less than your \n",
    "chosen significance level (e.g., 0.05), you can conclude that there is a significant main effect of that factor.\n",
    "\n",
    "If the p-value for the interaction effect (C(Software):C(Experience)) is significant, it suggests that the\n",
    "effect of software on task completion times depends on the employee's experience level, indicating an \n",
    "interaction effect.\n",
    "\n",
    "Carefully interpret the results in the context of your research question to determine the significance of \n",
    "each effect and whether there are any interactions between the factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e935c0-e815-4bfd-85da-59dd6a98bd0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fa2d702-003e-4cb5-a2ee-0c8efcdec117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-Sample T-Test Results:\n",
      "T-statistic: -1.6677351961320235\n",
      "P-value: 0.09856078338184605\n",
      "The results are not significant, indicating no difference between the groups.\n"
     ]
    }
   ],
   "source": [
    "#Q11\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "\n",
    "# Sample data (replace with your actual data)\n",
    "np.random.seed(0)  # For reproducibility\n",
    "control_group_scores = np.random.normal(75, 10, 50)  # Control group test scores\n",
    "experimental_group_scores = np.random.normal(80, 10, 50)  # Experimental group test scores\n",
    "\n",
    "# Perform a two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_group_scores, experimental_group_scores)\n",
    "\n",
    "# Print the results of the t-test\n",
    "print(\"Two-Sample T-Test Results:\")\n",
    "print(\"T-statistic:\", t_statistic)\n",
    "print(\"P-value:\", p_value)\n",
    "\n",
    "# Check if the results are significant (use a significance level, e.g., 0.05)\n",
    "if p_value < 0.05:\n",
    "    print(\"The results are significant, indicating a difference between the groups.\")\n",
    "    # Perform post-hoc tests (Tukey's HSD) to determine which group(s) differ significantly\n",
    "    data = pd.DataFrame({'Scores': np.concatenate([control_group_scores, experimental_group_scores]),\n",
    "                         'Group': np.repeat(['Control', 'Experimental'], 50)})\n",
    "    mc = MultiComparison(data['Scores'], data['Group'])\n",
    "    result = mc.tukeyhsd()\n",
    "    print(\"\\nPost-Hoc Test Results (Tukey's HSD):\")\n",
    "    print(result)\n",
    "else:\n",
    "    print(\"The results are not significant, indicating no difference between the groups.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eee688-c0e6-4848-a71a-1a04b58f6a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "Interpretation:\n",
    "\n",
    "If the p-value of the t-test is less than your chosen significance level (e.g., 0.05), you can \n",
    "conclude that there is a significant difference in test scores between the control and experimental \n",
    "groups.\n",
    "\n",
    "If the post-hoc test (Tukey's HSD) results are significant, it will indicate which specific \n",
    "group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3de240-b692-409c-aa9d-d696bdafc1a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2606dad-0252-4504-9593-99d2117de2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                sum_sq    df         F    PR(>F)\n",
      "C(Store)  4.014787e+06   2.0  1.721829  0.184773\n",
      "Residual  1.014289e+08  87.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "#Q12\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data (replace with your actual data)\n",
    "np.random.seed(0)  # For reproducibility\n",
    "store_A_sales = np.random.randint(1000, 5000, 30)  # Sales for Store A\n",
    "store_B_sales = np.random.randint(900, 4500, 30)   # Sales for Store B\n",
    "store_C_sales = np.random.randint(800, 4800, 30)   # Sales for Store C\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'Store': np.repeat(['A', 'B', 'C'], 30),\n",
    "    'Sales': np.concatenate([store_A_sales, store_B_sales, store_C_sales])\n",
    "})\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "formula = 'Sales ~ C(Store)'\n",
    "model = ols(formula, data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Print the ANOVA results\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e573335-bfb2-48ee-abcb-a80062ecba3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Now, interpret the results:\n",
    "\n",
    "If the p-value associated with the 'C(Store)' factor in the ANOVA table is less than your chosen \n",
    "significance level (e.g., 0.05), you can conclude that there are significant differences in daily \n",
    "sales between at least two of the stores."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
